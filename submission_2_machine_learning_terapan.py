# -*- coding: utf-8 -*-
"""Submission 2 Machine Learning Terapan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rvaijMGxVNLTjuSuZUSM5bPDAoeqXSI-

Mengimpor pustaka dan library yang dibutuhkan
"""

!pip install tensorflow

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import precision_recall_fscore_support
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

"""Mengambil dataset pada [Kaggle](https://www.kaggle.com/api/v1/datasets/download/arashnic/book-recommendation-dataset)"""

!curl -L -o book-recommendation-dataset.zip\
  "https://www.kaggle.com/api/v1/datasets/download/arashnic/book-recommendation-dataset"

"""Ekstraksi dataset"""

!unzip -q book-recommendation-dataset.zip -d /content/

"""Membuat dataframe"""

books = pd.read_csv("Books.csv")
ratings = pd.read_csv("Ratings.csv")

"""Setelah ditelusuri error terjadi karena ada data dalam Year-Of-Publication yang memiliki tipe string atau object"""

books['Year-Of-Publication'] = pd.to_numeric(books['Year-Of-Publication'], errors='coerce')
books = books.dropna(subset=['Year-Of-Publication'])
books['Year-Of-Publication'] = books['Year-Of-Publication'].astype(int)

books.head()

ratings.head()

"""Melihat jumlah baris unik pada masing-masing dataset"""

print('Jumlah unique value pada books:', len(books.ISBN.unique()))
print('Jumlah unique value pada ratings:', len(ratings.ISBN.unique()))

"""Berdasarkan hasil output, informasi yang diperoleh adalah sebagai berikut:

Variabel "books" berisi 271.360 jenis buku dan terdiri dari 8 kolom, yaitu:

- **ISBN**: Nomor identifikasi unik untuk buku.
- **Book-Title**: Judul buku.
- **Book-Author**: Nama penulis buku.
- **Year-Of-Publication**: Tahun penerbitan buku.
- **Publisher**: Nama penerbit buku.
- **Image-URL-S**: Tautan URL untuk gambar berukuran kecil.
- **Image-URL-M**: Tautan URL untuk gambar berukuran sedang.
- **Image-URL-L**: Tautan URL untuk gambar berukuran besar.

Variabel "ratings" berisi 340.556 penilaian untuk buku dan terdiri dari 3 kolom, yaitu:

- **User-ID**: Kode unik untuk pengguna anonim yang memberikan penilaian.
- **ISBN**: Nomor identifikasi buku.
- **Book-Rating**: Nilai atau rating yang diberikan untuk buku.
"""

books.info()

"""books_df kedua (tanpa nama) berisi 271359 entri dengan 8 kolom, semua kolom bertipe object kecuali Year-Of-Publication, dataset tanpa nilai null."""

ratings.info()

"""ratings_df berisi 1149780 entri dengan 3 kolom (User-ID, ISBN, Book-Rating) bertipe int64 dan object, tanpa nilai null.

Menghapus kolom-kolom yang tidak diperlukan
"""

books.drop(labels=['Image-URL-S', 'Image-URL-M', 'Image-URL-L'], axis=1, inplace=True)

"""Melihat author teratas dengan jumlah terbitan terbanyak"""

author_book_counts = books['Book-Author'].value_counts()

top_authors = author_book_counts.nlargest(10)

plt.figure(figsize=(10, 5))
top_authors.plot(kind='bar', color='tomato', edgecolor='black')
plt.title('Author teratas dengan terbitan terbanyak', fontsize=14, pad=15)
plt.xlabel('Author', fontsize=12)
plt.ylabel('Total Buku', fontsize=12)
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""Menggabungkan dataset ratings dengan books berdasarkan ISBN"""

books_df = pd.merge(ratings, books, on='ISBN', how='left')

books_df

"""Melihat null value pada dataframe"""

books_df.isnull().sum()

"""Dapat dilihat bahwa dataframe terdapat memiliki 1057 baris dengan beberapa kolom bernilai null"""

books_df = books_df.dropna()

"""Menghapus duplikasi data pada kolom ISBN"""

books_df = books_df.drop_duplicates('ISBN')

"""Mengambil 10000 data karena keterbatasan compute power"""

books_df = books_df.sample(10000, random_state=52, ignore_index=True)

books_df

fix_books_df = pd.DataFrame({
    'isbn': books_df['ISBN'],
    'book_title': books_df['Book-Title'],
    'book_author': books_df['Book-Author'],
    'publication_year': books_df['Year-Of-Publication'],
    'publisher': books_df['Publisher'],
    'book_rating': books_df['Book-Rating']
})

"""Menyiapkan data untuk model development"""

tf = TfidfVectorizer()
tf.fit(fix_books_df['book_author'])
tfidf_matrix = tf.fit_transform(fix_books_df['book_author'])
tfidf_matrix.shape

tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=fix_books_df.book_title
).sample(15, axis=1).sample(10, axis=0)

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

cosine_df = pd.DataFrame(cosine_sim, index=fix_books_df['book_title'], columns=fix_books_df['book_title'])
cosine_df.head()

"""Kode ini mengimplementasikan sistem rekomendasi buku berdasarkan kesamaan kosinus (cosine similarity). Diberikan judul buku, fungsi ini merekomendasikan k buku yang mirip menggunakan matriks kesamaan kosinus (similarity_data) dan dataset (items) yang berisi judul buku dan penulis.


1. **Parameter Masukan**:
   - book_title: Judul buku yang ingin dicari rekomendasinya.
   - similarity_data: DataFrame yang berisi skor kesamaan kosinus antar buku (default: cosine_sim_df).
   - items: DataFrame yang berisi metadata buku, yaitu book_title dan book_author (default: data[['book_title', 'book_author']]).
   - k: Jumlah rekomendasi yang akan dikembalikan (default: 5).

2. **Proses**:
   - Fungsi mengambil skor kesamaan untuk book_title dari matriks similarity_data.
   - Mengidentifikasi indeks dari k buku yang paling mirip menggunakan mekanisme pengurutan.
   - Judul buku masukan dikeluarkan dari daftar rekomendasi agar tidak muncul.
   - Menggabungkan judul buku yang dipilih dengan metadata (misalnya, penulis) dari DataFrame items dan mengembalikan k rekomendasi teratas.

3. **Keluaran**:
   - DataFrame yang berisi k buku yang direkomendasikan, lengkap dengan judul dan penulisnya.


Implementasi alternatif di bawah ini menggunakan pendekatan pengurutan dan penyaringan yang berbeda dari kode asli, tetapi tetap menghasilkan fungsi yang sama.
"""

def book_recommendation(book_title, similarity_data=cosine_df, items=fix_books_df[['book_title', 'book_author']], k=5):
    """
    Merekomendasikan k buku yang mirip berdasarkan kesamaan kosinus.

    Parameter:
    - book_title (str): Judul buku untuk mencari rekomendasi.
    - similarity_data (pd.DataFrame): DataFrame berisi skor kesamaan kosinus antar buku.
    - items (pd.DataFrame): DataFrame berisi metadata buku (book_title, book_author).
    - k (int): Jumlah rekomendasi yang dikembalikan (default: 5).

    Mengembalikan:
    - pd.DataFrame: k buku yang direkomendasikan dengan judul dan penulisnya, atau pesan error jika judul tidak ditemukan.
    """

    if book_title not in similarity_data.columns:
        print (f"Judul buku '{book_title}' tidak ditemukan dalam fix_books_df.")
        return

    sim_scores = similarity_data[book_title].to_numpy()
    top_indices = np.argsort(sim_scores)[::-1][:k+1]
    top_books = similarity_data.columns[top_indices]
    top_books = [title for title in top_books if title != book_title][:k]
    recommendations = pd.DataFrame(top_books, columns=['book_title'])
    result = recommendations.merge(items, on='book_title', how='left')

    return result.head(k)

book_recommendation("The Unicorn Solution")

def evaluate_recommendation_metrics(cosine_sim, fix_books_df, sample_size=10000, threshold=0.5):
    """
    Mengevaluasi metrik precision, recall, dan f1-score untuk sistem rekomendasi berdasarkan matriks kesamaan kosinus.

    Parameter:
    - cosine_sim (np.ndarray): Matriks kesamaan kosinus antar buku.
    - fix_books_df (pd.DataFrame): DataFrame berisi metadata buku dengan kolom 'book_title'.
    - sample_size (int): Ukuran sampel dari matriks kesamaan untuk evaluasi (default: 10000).
    - threshold (float): Ambang batas untuk mengkategorikan kesamaan sebagai 1 atau 0 (default: 0.5).

    Mengembalikan:
    - dict: Metrik evaluasi (precision, recall, f1-score) dan sampel ground truth.
    """


    sample_size = min(sample_size, cosine_sim.shape[0], cosine_sim.shape[1])
    ground_truth = np.where(cosine_sim >= threshold, 1, 0)
    cosine_sim_sample = cosine_sim[:sample_size, :sample_size]
    ground_truth_sample = ground_truth[:sample_size, :sample_size]
    cosine_sim_flat = cosine_sim_sample.flatten()
    ground_truth_flat = ground_truth_sample.flatten()
    predictions = (cosine_sim_flat >= threshold).astype(int)

    precision, recall, f1, _ = precision_recall_fscore_support(
        ground_truth_flat, predictions, average='binary', zero_division=1
    )

    ground_truth_df = pd.DataFrame(
        ground_truth_sample,
        index=fix_books_df['book_title'][:sample_size],
        columns=fix_books_df['book_title'][:sample_size]
    ).sample(5, axis=1).sample(10, axis=0)

    return {
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
    }

metrics = evaluate_recommendation_metrics(cosine_sim, fix_books_df)
print("Precision:", metrics['precision'])
print("Recall:", metrics['recall'])
print("F1-score:", metrics['f1_score'])